// Skills section data

export const skillsSection = {
  display: true,
  title: "Evolution Over Engineering",
  subtitle: {
    highlightedText: "Where everyone sees failure, I see evolution at work",
    normalText:
      "—Building AI that assembles components, not memorizes patterns. Because intelligence is about adaptative behavior, not accuracy.",
  },
  skills: [
    "Connecting neuroscience, physics, psychology, and engineering to understand intelligence.",
    "Hyperparameter optimization through systematic exploration, billions of configurations tested.",
    "Reducing 7-year bottlenecks to 6-month pipelines.",
    "When tools don't exist, I create them. From research pipelines to evolutionary frameworks.",
    "Publishing rigorous research on unconventional approaches.",
    "Helping students think systematically about complex problems.",
    "Breaking complex systems into components, understanding interactions, rebuilding understanding.",
    "Python, JAX, NumPy, PyTorch, distributed computing, performance optimization.",
    "ES-HyperNEAT, NEAT, CPPNs, population-based optimization.",
    "Five years pursuing one insight through multiple paradigms with systematic execution.",
    "Every 'wrong' approach revealed essential constraints and possibilities.",
    "Understanding when to stop controlling and start observing.",
    "From papers to documentation to making complex ideas accessible.",
    "Sharing tools, frameworks, and research code with the community.",
    "Willing to spend years on problems others abandon after months.",
  ],
  // Core Expertise section configuration
  coreExpertiseSection: {
    title: "Core Expertise",
    subtitle:
      "Breeding neural networks that surprise me—because real intelligence disobeys its creator.",
  },
  // Core activities with associated technologies
  coreActivities: [
    {
      icon: "🧬",
      title: "Evolutionary AI: Growing Intelligence, Not Training It",
      description:
        "While everyone's optimizing gradients, I'm evolving behaviors. Slower? Yes. More compute? Absolutely. But mine adapt when yours break.",
      expandedDescription:
        "Started with graph-based reasoning systems in 2020—before the transformer revolution. Realized we're building high-performing dead ends: 99.9% accuracy that dies on the 100.1% case. Explored symbolic reasoning, distributed agents, fuzzy logic—each 'detour' revealed the same truth: intelligence isn't trained, it's grown. Now I evolve neural networks that discover behaviors I never programmed. Published research: 29% MNIST accuracy that spontaneously transfers to Fashion-MNIST. Not because I told them to—because they evolved general features, not task-specific memorization. Your model needs retraining for every variation. Mine adapts because that's what evolution does—it survives change.",
      technologies: ["NEAT/CPPNs", "JAX/TensorNEAT"],
    },
    {
      icon: "🔬",
      title: "Research Through Systematic Exploration",
      description:
        "Used more CPU hours than sensible. Beat state-of-art. Still 'only' 29%. That's when you know you're onto something fundamental.",
      expandedDescription:
        "I don't train networks—I breed populations. Each generation: mutations, selection pressure, survival of the most adaptable (not the most accurate). My networks achieve 29% on MNIST—groundbreaking for neuroevolution, beating the previous 23.90% benchmark. But here's what matters: they transfer to new tasks without retraining. Like biological systems adapting to new environments. Currently developing methods to make evolution 100-1000x faster through systematic optimization. Because waiting years to discover failure isn't research—it's masochism. Published at GECCO'24: proving systematic exploration beats random search, every time.",
      technologies: ["Hyperparameter Optimization", "Distributed Computing"],
    },
    {
      icon: "🤖",
      title: "Compositional Intelligence: AI That Thinks in Parts",
      description:
        "My networks solve problems by assembling solutions from components. Not elegant. Not efficient. But interpretable and adaptable.",
      expandedDescription:
        "Five years converging on this insight: Intelligence is compositional, not monolithic. Humans don't memorize—we decompose, process, recompose. My research builds AI that thinks the same way. Networks that evolve specialized components, then learn to orchestrate them. They develop unexpected strategies: edge detectors here, pattern matchers there, weird routing behaviors I never designed. Remove connections? They route around damage. Change the task? They repurpose components. It's messy, redundant, and absolutely fascinating. Traditional AI gives you clean architectures that shatter on edge cases. Mine are biological messes that refuse to die. That's not a bug—that's intelligence.",
      technologies: ["Compositional Architectures", "Emergent Behaviors"],
    },
  ],
  frameworks: [
    "PUREPLES (until I killed it)",
    "TENSORNEAT (in therapy together)",
    "JAX (it's complicated)",
    "PyTorch (baselines to beat)",
    "NumPy (old reliable)",
    "Optuna (hyperparameter sadism)",
    "Your framework (if it survives)",
  ],
  languages: [
    { language: "French", proficiency: "Native", flag: "🇫🇷" },
    { language: "English", proficiency: "Academic", flag: "🇬🇧" },
    { language: "Russian", proficiency: "Семья", flag: "🇷🇺" },
    { language: "German", proficiency: "Fast Schweizerdeutsch", flag: "🇩🇪" },
    { language: "Python", proficiency: "Abusive Relationship", flag: "🐍" },
    { language: "Math", proficiency: "When Cornered", flag: "∑" },
  ],
  // Research Philosophy section configuration
  researchPhilosophySection: {
    title: "Research Philosophy",
    subtitle: "Building AI that adapts, not memorizes",
  },
  researchInterests: {
    "Current Focus": [
      "Compositional AI: Assemble solutions from evolved components",
      "Making evolution viable: Years → months → days",
      "Transfer without retraining: Behaviors, not weights",
      "Interpretable through decomposition",
    ],
    "Why Evolution": [
      "Cockroaches outlived dinosaurs—adaptation beats optimization",
      "Your brain: 20W of spaghetti code that works",
      "Every biological 'bug' is a feature somewhere else",
      "Messy survivors beat clean corpses",
    ],
    "My Approach": [
      "Test systematically or waste compute",
      "Behaviors evolve, weights just memorize",
      "Adaptability > benchmark scores",
      "Failures are data, not mistakes",
    ],
    Seeking: [
      "Collaborators who value adaptation over benchmarks",
      "Patience to let evolution surprise you",
      "Understanding that intelligence emerges, isn't programmed",
      "Building for the unknown, not the test set",
    ],
  },
};
